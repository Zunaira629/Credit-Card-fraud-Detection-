{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310,"isSourceIdPinned":false}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"Credit Card Fraud Detection\nDate: October 5, 2025\nName: Zunaira Asif\n\nThis project detects fraudulent transactions using **Logistic Regression** on a real-world credit card dataset.\n\nNotebook Covers:\n\n1. Data Loading & Exploration\n2. Data Cleaning & Balancing\n3. Feature Scaling\n4. Trainâ€“Test Split\n5. Logistic Regression Modeling\n6. Model Training & Prediction\n7. Model Evaluation (Accuracy, Precision, Recall, F1, AUC)\n8. Visualization of Confusion Matrix & ROC Curve\n\nItâ€™s a beginner-friendly example showing how machine learning helps identify fraud patterns effectively.\n\nResults:\nðŸ“Š Accuracy: 99.9%â€ƒ|â€ƒPrecision: 93%â€ƒ|â€ƒRecall: 89% â†’ The model detects frauds with high accuracy and reliability!","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"import kagglehub\n\n# Download latest version of the dataset\npath = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n\nprint(\"Path to dataset files:\", path)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2025-09-25T16:36:58.666611Z","iopub.execute_input":"2025-09-25T16:36:58.667221Z","iopub.status.idle":"2025-09-25T16:36:58.681745Z","shell.execute_reply.started":"2025-09-25T16:36:58.667192Z","shell.execute_reply":"2025-09-25T16:36:58.680598Z"}},"attachments":{}},{"cell_type":"code","source":"# 1. Title & Problem Statement\nprint(\"ðŸ’³ Credit Card Fraud Detection\")\n\n# 2. Load Data & Dataset Description\nimport kagglehub\nimport pandas as pd\n\n# Download dataset\npath = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n\n# Load dataset\ndf = pd.read_csv(f\"{path}/creditcard.csv\")\nprint(\"Dataset shape:\", df.shape)\nprint(\"\\nClass distribution:\\n\", df['Class'].value_counts())\nprint(\"\\nDataset statistics:\\n\", df.describe())\n\n# 3. Exploratory Data Analysis (EDA)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Check & Handle Missing Values\nprint(\"\\nChecking for Missing Values:\")\nprint(df.isnull().sum())\n\n# Fill missing values with median (if any)\ndf = df.fillna(df.median())\nprint(\"\\n Missing Values (if any) handled.\")\n#  Basic Data Information\nprint(\"\\nClass Distribution (0 = Non-Fraud, 1 = Fraud):\\n\", df['Class'].value_counts())\n\n# Now import matplotlib (only where needed)\nimport matplotlib.pyplot as plt\n\n# Pie Chart for class distribution\nplt.figure(figsize=(5,5))\ndf['Class'].value_counts().plot.pie(\n    autopct='%1.2f%%', labels=['Non-Fraud', 'Fraud'], colors=['skyblue', 'lightcoral'])\nplt.title(\"Fraud vs Non-Fraud Transactions\")\nplt.ylabel(\"\")\nplt.show()\n#  Feature Scaling\n# Separate features and target\nX = df.drop(\"Class\", axis=1)\ny = df[\"Class\"]\n\n# Import StandardScaler only here\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX[['Time', 'Amount']] = scaler.fit_transform(X[['Time', 'Amount']])\nprint(\"\\n Feature Scaling applied on Time and Amount.\")\n#  Split Data\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y)\nprint(\"\\n Data Split into Training and Testing Sets.\")\n#  Train Model\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(max_iter=500)\nmodel.fit(X_train, y_train)\nprint(\"\\n Logistic Regression Model Trained Successfully.\")\n#  Predictions\ny_pred = model.predict(X_test)\n#  Evaluate Model\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n\n# For ROC score, we need prediction probabilities\ny_prob = model.predict_proba(X_test)[:, 1]\nprint(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))\n#  Confusion Matrix Graph\nimport seaborn as sns\n\nplt.figure(figsize=(4,3))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='coolwarm')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n#  ROC Curve\nfrom sklearn.metrics import roc_curve\n\nfpr, tpr, _ = roc_curve(y_test, y_prob)\nplt.plot(fpr, tpr, color='blue', label='Logistic Regression')\nplt.plot([0,1], [0,1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend()\nplt.show()\n#  Test on One Sample\nsample = X_test.iloc[[0]]\nprint(\"\\nTesting on one transaction sample:\\n\", sample)\nprediction = model.predict(sample)[0]\nprint(\"\\nPredicted Class (0 = Non-Fraud, 1 = Fraud):\", prediction)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:50:05.403151Z","iopub.execute_input":"2025-10-05T02:50:05.404034Z","iopub.status.idle":"2025-10-05T02:50:20.652667Z","shell.execute_reply.started":"2025-10-05T02:50:05.404008Z","shell.execute_reply":"2025-10-05T02:50:20.651795Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}